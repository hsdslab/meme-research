{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Murgi\\code\\memes2024\\meme-research-2024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Murgi\\code\\memes2024\\meme-research-2024\\phash\\lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%pwd\n",
    "%cd d:\\\\Murgi\\\\code\\\\memes2024\\\\meme-research-2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import normalize\n",
    "import time\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.linear_model import Lasso, LassoLars\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "meme_df = pd.read_parquet('./data/meme_entries.parquet')\n",
    "template_df = pd.read_parquet('./data/meme_template_links.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample only 30 images from each template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>template_name</th>\n",
       "      <th>path</th>\n",
       "      <th>phash</th>\n",
       "      <th>template_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-days-without-Lenny-Simpsons_85</td>\n",
       "      <td>0-days-without-lenny-simpsons</td>\n",
       "      <td>D:/Memes2024/0-days-without-Lenny-Simpsons/0-d...</td>\n",
       "      <td>07e5b23ee806f638</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0-days-without-Lenny-Simpsons_10</td>\n",
       "      <td>0-days-without-lenny-simpsons</td>\n",
       "      <td>D:/Memes2024/0-days-without-Lenny-Simpsons/0-d...</td>\n",
       "      <td>17e5b22ee806fe30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0-days-without-Lenny-Simpsons_51</td>\n",
       "      <td>0-days-without-lenny-simpsons</td>\n",
       "      <td>D:/Memes2024/0-days-without-Lenny-Simpsons/0-d...</td>\n",
       "      <td>0fedb236e806fa30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0-days-without-Lenny-Simpsons_76</td>\n",
       "      <td>0-days-without-lenny-simpsons</td>\n",
       "      <td>D:/Memes2024/0-days-without-Lenny-Simpsons/0-d...</td>\n",
       "      <td>07edb21ee806fa38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0-days-without-Lenny-Simpsons_29</td>\n",
       "      <td>0-days-without-lenny-simpsons</td>\n",
       "      <td>D:/Memes2024/0-days-without-Lenny-Simpsons/0-d...</td>\n",
       "      <td>0fe1ba36e806fa38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34345</th>\n",
       "      <td>Zuckerberg_28</td>\n",
       "      <td>zuckerberg</td>\n",
       "      <td>D:/Memes2024/Zuckerberg/Zuckerberg_28.jpg</td>\n",
       "      <td>734c93a7266631cd</td>\n",
       "      <td>1145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34346</th>\n",
       "      <td>Zuckerberg_10</td>\n",
       "      <td>zuckerberg</td>\n",
       "      <td>D:/Memes2024/Zuckerberg/Zuckerberg_10.jpg</td>\n",
       "      <td>734889a727e331e5</td>\n",
       "      <td>1145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34347</th>\n",
       "      <td>Zuckerberg_39</td>\n",
       "      <td>zuckerberg</td>\n",
       "      <td>D:/Memes2024/Zuckerberg/Zuckerberg_39.jpg</td>\n",
       "      <td>7148c9a72de23d65</td>\n",
       "      <td>1145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34348</th>\n",
       "      <td>Zuckerberg_6</td>\n",
       "      <td>zuckerberg</td>\n",
       "      <td>D:/Memes2024/Zuckerberg/Zuckerberg_6.jpg</td>\n",
       "      <td>7148db7324c73372</td>\n",
       "      <td>1145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34349</th>\n",
       "      <td>Zuckerberg_11</td>\n",
       "      <td>zuckerberg</td>\n",
       "      <td>D:/Memes2024/Zuckerberg/Zuckerberg_11.jpg</td>\n",
       "      <td>f30cd9344ce73334</td>\n",
       "      <td>1145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34350 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id                  template_name  \\\n",
       "0      0-days-without-Lenny-Simpsons_85  0-days-without-lenny-simpsons   \n",
       "1      0-days-without-Lenny-Simpsons_10  0-days-without-lenny-simpsons   \n",
       "2      0-days-without-Lenny-Simpsons_51  0-days-without-lenny-simpsons   \n",
       "3      0-days-without-Lenny-Simpsons_76  0-days-without-lenny-simpsons   \n",
       "4      0-days-without-Lenny-Simpsons_29  0-days-without-lenny-simpsons   \n",
       "...                                 ...                            ...   \n",
       "34345                     Zuckerberg_28                     zuckerberg   \n",
       "34346                     Zuckerberg_10                     zuckerberg   \n",
       "34347                     Zuckerberg_39                     zuckerberg   \n",
       "34348                      Zuckerberg_6                     zuckerberg   \n",
       "34349                     Zuckerberg_11                     zuckerberg   \n",
       "\n",
       "                                                    path             phash  \\\n",
       "0      D:/Memes2024/0-days-without-Lenny-Simpsons/0-d...  07e5b23ee806f638   \n",
       "1      D:/Memes2024/0-days-without-Lenny-Simpsons/0-d...  17e5b22ee806fe30   \n",
       "2      D:/Memes2024/0-days-without-Lenny-Simpsons/0-d...  0fedb236e806fa30   \n",
       "3      D:/Memes2024/0-days-without-Lenny-Simpsons/0-d...  07edb21ee806fa38   \n",
       "4      D:/Memes2024/0-days-without-Lenny-Simpsons/0-d...  0fe1ba36e806fa38   \n",
       "...                                                  ...               ...   \n",
       "34345          D:/Memes2024/Zuckerberg/Zuckerberg_28.jpg  734c93a7266631cd   \n",
       "34346          D:/Memes2024/Zuckerberg/Zuckerberg_10.jpg  734889a727e331e5   \n",
       "34347          D:/Memes2024/Zuckerberg/Zuckerberg_39.jpg  7148c9a72de23d65   \n",
       "34348           D:/Memes2024/Zuckerberg/Zuckerberg_6.jpg  7148db7324c73372   \n",
       "34349          D:/Memes2024/Zuckerberg/Zuckerberg_11.jpg  f30cd9344ce73334   \n",
       "\n",
       "       template_id  \n",
       "0                1  \n",
       "1                1  \n",
       "2                1  \n",
       "3                1  \n",
       "4                1  \n",
       "...            ...  \n",
       "34345         1145  \n",
       "34346         1145  \n",
       "34347         1145  \n",
       "34348         1145  \n",
       "34349         1145  \n",
       "\n",
       "[34350 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode template name\n",
    "labelencoder = LabelEncoder()\n",
    "meme_df['template_id'] = labelencoder.fit_transform(meme_df['template_name'])\n",
    "meme_df['template_id'] = meme_df['template_id'] + 1\n",
    "sample_size = 30\n",
    "sampled_meme_df = meme_df.groupby('template_name').apply(lambda x: x.sample(n=min(sample_size, len(x)),random_state=42))\n",
    "sampled_meme_df = sampled_meme_df.reset_index(drop=True)\n",
    "sampled_meme_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions will make computations easier. They are inspired by the articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta(x,i,class_num):\n",
    "    '''\n",
    "    Function that selects the coefficients associated with the ith class\n",
    "    Useful for SCI calculation\n",
    "    m: number of samples\n",
    "    - x: vector of coefficients, shape (m,)\n",
    "    - i: class index\n",
    "    - class_num: vector of training labels, shape (m,)\n",
    "    '''\n",
    "    n,m = len(x),len(class_num)\n",
    "    \n",
    "    if (n != m):\n",
    "        print('Vectors of differents sizes')\n",
    "        \n",
    "    tmp = i*np.ones(n)-class_num\n",
    "\n",
    "    for k in range(n):\n",
    "        if tmp[k]==0:\n",
    "            tmp[k]=1\n",
    "        else:\n",
    "            tmp[k]=0 \n",
    "    \n",
    "    return tmp*x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorized version of the delta function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta_vectorized(x, class_num):\n",
    "    '''\n",
    "    Function that selects the coefficients associated with the ith class\n",
    "    Useful for SCI calculation\n",
    "    m: number of samples\n",
    "    - x: vector of coefficients, shape (m,)\n",
    "    - class_num: vector of training labels, shape (m,)\n",
    "    '''\n",
    "    n, m = len(x), len(class_num)\n",
    "    \n",
    "    if (n != m):\n",
    "        print('Vectors of different sizes')\n",
    "\n",
    "    k = np.max(class_num)+1\n",
    "\n",
    "    tmp = np.subtract(np.multiply(np.ones((n, k)),np.arange(k)),class_num[:, np.newaxis])\n",
    "    tmp = np.where(tmp == 0, 1, 0)\n",
    "    \n",
    "    return (tmp * x[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the vectorized delta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 6. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 6. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 6. 6. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 6. 6. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 7.]]\n",
      "[[6 0 0 0 0 0 0 0]\n",
      " [0 6 0 0 0 0 0 0]\n",
      " [0 0 6 0 0 0 0 0]\n",
      " [0 0 0 6 6 0 0 0]\n",
      " [0 0 0 0 0 6 6 0]\n",
      " [0 0 0 0 0 0 0 7]]\n",
      "Test passed!\n",
      "[[6. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 6. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 6. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 6. 6. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 6. 6.]]\n",
      "[[6 0 0 0 0 0 0]\n",
      " [0 6 0 0 0 0 0]\n",
      " [0 0 6 0 0 0 0]\n",
      " [0 0 0 6 6 0 0]\n",
      " [0 0 0 0 0 6 6]]\n",
      "Test passed!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def test_delta(x,class_num):\n",
    "    # number of classes\n",
    "    k = np.max(class_num)+1\n",
    "\n",
    "    # Original function\n",
    "    result1 = None\n",
    "    for i in range(0,k):\n",
    "        temp = delta(x, i, class_num)\n",
    "        if i == 0:\n",
    "            result1 = np.array(temp)\n",
    "        else:\n",
    "            result1 = np.append(result1, temp)\n",
    "\n",
    "    result1 = result1.reshape(k, len(x))\n",
    "\n",
    "    # Vectorized function\n",
    "    result2 = delta_vectorized(x, class_num).T # We transpose here but this is not necessary in the main algorithm because of the dot product afterwards\n",
    "\n",
    "    # Compare the results\n",
    "    print(result1)\n",
    "    print(result2)\n",
    "    assert np.array_equal(result1, result2), \"Results are not equal\"\n",
    "    print(\"Test passed!\")\n",
    "\n",
    "\n",
    "# labels of the samples\n",
    "class_num_1 = np.array([0, 1, 2, 3, 3, 4, 4, 5])\n",
    "# coefficients of the samples\n",
    "x_1 = np.array([6, 6, 6, 6, 6, 6, 6, 7])\n",
    "\n",
    "test_delta(x_1, class_num_1)\n",
    "\n",
    "class_num_2 = np.array([0, 1, 2, 3, 3, 4, 4])\n",
    "x_2 = np.array([6, 6, 6, 6, 6, 6, 6])\n",
    "\n",
    "test_delta(x_2, class_num_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual(y,A,x,class_x):\n",
    "    '''\n",
    "    Returns the residuals of the model for each class\n",
    "    n: number of features, m: number of samples\n",
    "    - y: the target vector, shape (n,)\n",
    "    - A: training images, shape (n, m)\n",
    "    - x: the coefficients, shape (m,)\n",
    "    - class_x: the train labels, shape: (m,) type: list\n",
    "    '''\n",
    "    k = np.max(class_x)+1\n",
    "    r = np.zeros(k)\n",
    "    \n",
    "    for i in range(0,k):\n",
    "        r[i] = np.linalg.norm(y - np.dot(A,delta(x,i,class_x)))        \n",
    "    return r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorized version of the residual function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_vectorized(y, A, x, class_x):\n",
    "    '''\n",
    "    Returns the residuals of the model for each class\n",
    "    n: number of features, m: number of samples\n",
    "    - y: the target vector, shape (n,)\n",
    "    - A: training images, shape (n, m)\n",
    "    - x: the coefficients, shape (m,)\n",
    "    - class_x: the train labels, shape: (m,) type: list\n",
    "    '''\n",
    "    # Generate the delta matrix for all classes\n",
    "    delta_matrix = delta_vectorized(x, class_x)\n",
    "    \n",
    "    # Compute the predicted values for each class\n",
    "    predictions = np.dot(A, delta_matrix)\n",
    "    \n",
    "    # Calculate the errors by subtracting y from each column of predictions\n",
    "    # Note: Need to reshape y to broadcast correctly against predictions\n",
    "    errors = predictions - y.reshape(-1, 1)\n",
    "    \n",
    "    # Calculate the norm of errors for each class to get the residuals\n",
    "    r = np.linalg.norm(errors, axis=0)\n",
    "    \n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the vectorized residual function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.74165739 5.38516481]\n",
      "[3.74165739 5.38516481]\n",
      "Test passed!\n"
     ]
    }
   ],
   "source": [
    "def test_residual(y, A, x, class_x):\n",
    "    # Original function\n",
    "    result1 = residual(y, A, x, class_x)\n",
    "\n",
    "    # Vectorized function\n",
    "    result2 = residual_vectorized(y, A, x, class_x)\n",
    "\n",
    "    # Compare the results\n",
    "    print(result1)\n",
    "    print(result2)\n",
    "    assert np.array_equal(result1, result2), \"Results are not equal\"\n",
    "    print(\"Test passed!\")\n",
    "\n",
    "# Test the function\n",
    "y = np.array([1, 2, 3])\n",
    "A = np.array([[1, 1], [1, 1], [1, 1]])\n",
    "x = np.array([4, 5])\n",
    "class_x = np.array([0, 1])\n",
    "\n",
    "test_residual(y, A, x, class_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SCI function implements the Sparsity Concentration Index (with $k$ number of classes and $\\delta_{i}$ the indicator of i-th class)  :\n",
    "\n",
    "$$SCI(x)=\\frac{k*max_i  \\frac{\\|\\delta_{i}(x)\\|_{1}}{\\|x\\|_{1}}-1}{k-1}$$\n",
    "\n",
    "It is used to filter out bad images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SCI(x,class_num):\n",
    "    '''\n",
    "    - class_num: classe of a training element.\n",
    "    - x        : sparse coefficients\n",
    "    '''\n",
    "    \n",
    "    k = len(set(class_num)) # Number of different classes\n",
    "    \n",
    "    return (k*(1/np.linalg.norm(x,ord=1))*np.max([np.linalg.norm(delta(x,i,class_num),ord=1) for i in range(k)]) - 1)/(k-1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we stack the images into vectors and concatenate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack(X_train,X_test):\n",
    "    X_toconcat_train = [np.reshape(e,(X_train[0].shape[0]*X_train[0].shape[1],1)) for e in X_train]\n",
    "    X_toconcat_test = [np.reshape(e,(X_train[0].shape[0]*X_train[0].shape[1],1)) for e in X_test]\n",
    "    \n",
    "    Xtrain = np.concatenate(X_toconcat_train,axis=1) # Each column is now an image of the train set\n",
    "    Xtest = np.concatenate(X_toconcat_test,axis=1) # Each column is now an image of the test set\n",
    "\n",
    "    return Xtrain,Xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images(meme_df, target_size=(64,64), filter=Image.LANCZOS):\n",
    "    '''\n",
    "    Read the images from the meme_df dataframe and return the images and the labels\n",
    "    - meme_df: dataframe containing the path to the images and the template_id\n",
    "    - target_size: size of the output images (default is (128,128))\n",
    "    - filter: filter to use for resizing (default is Image.LANCZOS)\n",
    "    '''\n",
    "    path_list = meme_df['path'].tolist()\n",
    "    template_list = meme_df['template_id'].tolist()\n",
    "    X,y = [], []\n",
    "    for (path, template) in tqdm(zip(path_list, template_list), total= len(path_list)):\n",
    "        try:\n",
    "            im = Image.open(path) \n",
    "            im = im.convert(\"L\")\n",
    "            # resize to given size (if given) and check that it's the good size\n",
    "            im = im.resize(target_size, resample=filter)\n",
    "            X.append(np.asarray(im, dtype=np.uint8))\n",
    "            y.append(template)\n",
    "        except IOError:\n",
    "            pass\n",
    "        except:\n",
    "            print(\"Unexpected error:\", sys.exc_info()[0])\n",
    "            raise\n",
    "    print(\"Images uploaded !\")\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def read_image(path, target_size=(64,64), filter=Image.NEAREST):\n",
    "    im = Image.open(path) \n",
    "    im = im.convert(\"L\")\n",
    "    # resize to given size (if given) and check that it's the good size\n",
    "    im = im.resize(target_size, resample=filter)\n",
    "    return np.asarray(im, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data if already read, else read the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load\n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "save_path_X = \"./data/X_original_64x64_sampled_30.pkl\"\n",
    "save_path_y = \"./data/y_original_64x64_sampled_30.pkl\"\n",
    "load_df = sampled_meme_df\n",
    "\n",
    "if os.path.exists(save_path_X):\n",
    "    print(\"Load\")\n",
    "    X_original = pkl.load(open(save_path_X, 'rb'))\n",
    "    y_original = pkl.load(open(save_path_y, 'rb'))\n",
    "\n",
    "else:\n",
    "    # X_original, y_original = read_images(load_df, filter=Image.NEAREST)\n",
    "    with open(save_path_X, 'wb') as f:\n",
    "        pkl.dump(X_original, f)\n",
    "\n",
    "    with open(save_path_y, 'wb') as f:\n",
    "        pkl.dump(y_original, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whole Algorithm Commented (we will use only one function instead of pasting as many times as there are test sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Here we implement the algorithm 1 of the paper (relaxed version)\n",
    "\t\n",
    "- Input : a matrix of training samples $A=\\lbrack A_{1},A_{2},...,A_{k} \\rbrack \\in \\mathbb{R}^{m \\times n}$ for k classes and a test sample $y \\in \\mathbb{R}^{m}$\n",
    "- Normalize the columns of A to have unit $L^{2}$ norm\n",
    "- Solve the $L^{1}$ minimization problem : $\\hat{x_{1}}= argmin \\|x\\|_{1}$   sc  $\\|Ax-y\\|_{2} \\leq \\epsilon$\t\t\n",
    "- Compute the residuals\n",
    "\t$ \\mbox{ for all } i=1,...k, r_{i}(y)=\\|y-A\\delta_{i}(\\hat{x_{1}})\\|_{2}$\n",
    "\t\n",
    "- $\\mathcal{C}_{y}=argmin_{i} r_{i}(y)$\n",
    "\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example from original notebook\n",
    "\n",
    "Test_pic varies, it depends what the test set is (sunglasses, scarves, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pic = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = Lasso(alpha=4)\n",
    "\n",
    "# y = Xtest[:,test_pic]\n",
    "\n",
    "# clf.fit(Xtrain,y)\n",
    "# x = clf.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Results **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_class = np.argmin(residual(Xtest[:,test_pic],Xtrain,x,ytrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real class:  0\n",
      "Predicted class:  0\n",
      "SCI :  1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Real class: \", ytest[test_pic])\n",
    "print(\"Predicted class: \", pred_class)\n",
    "print(\"SCI : \", SCI(x,ytrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseMatchingClassifier:\n",
    "    def __init__(self, alpha=4):\n",
    "        self.alpha = alpha\n",
    "        self.clf = Lasso(alpha=self.alpha)\n",
    "    \n",
    "    def fit_transform(self,X_train,y, y_train):\n",
    "        self.clf.fit(X_train,y)\n",
    "        self.y_train = y_train\n",
    "        self.x = self.clf.coef_\n",
    "\n",
    "        pred_class = np.argmin(residual(y,X_train,self.x,y_train))\n",
    "\n",
    "        return pred_class\n",
    "\n",
    "    def SCI(self):\n",
    "        return SCI(self.x,self.y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the solution is really really sparse, that's work !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'Class')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1610049c390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.clf()\n",
    "plt.bar(range(50),residual(Xtest[:,test_pic],Xtrain,x,ytrain))\n",
    "plt.title('Residuals for each class. Predicted class coeff rejection ' + str(np.round(SCI(x,ytrain),2)))\n",
    "plt.ylabel('Residuals')\n",
    "plt.xlabel('Class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   1    2    3 ... 1143 1144 1145]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(np.unique(y_original))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_original, y_original, test_size=0.2, random_state=42, stratify=y_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34350, 64, 64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_original.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4096, 27480)\n",
      "(4096, 27480)\n",
      "(4096, 6870)\n",
      "4096\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train, X_test = stack(X_train,X_test)\n",
    "print(X_train.shape)\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_train.T) # We need to transpose the matrix because the StandardScaler expects the samples to be the rows\n",
    "X_train = ss.transform(X_train.T).T\n",
    "X_test = ss.transform(X_test.T).T\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(ss.n_features_in_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4096, 27480), (4096, 6870), (34350, 64, 64))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, X_original.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 800\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m clf\u001b[38;5;241m.\u001b[39mfit(X_train,example_y)\n\u001b[0;32m     12\u001b[0m x \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mcoef_\n\u001b[1;32m---> 13\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmin(\u001b[43mresidual\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(y_pred, y_test[i])\n",
      "Cell \u001b[1;32mIn[11], line 14\u001b[0m, in \u001b[0;36mresidual\u001b[1;34m(y, A, x, class_x)\u001b[0m\n\u001b[0;32m     11\u001b[0m r \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(k)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,k):\n\u001b[1;32m---> 14\u001b[0m     r[i] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(y \u001b[38;5;241m-\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43mclass_x\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)        \n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "max_idx = X_test.shape[1]\n",
    "\n",
    "# get 10 random indexes\n",
    "# random_idx = random.sample(range(0, max_idx), 10)\n",
    "random_idx = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "for i in random_idx:\n",
    "    example_y = X_test[:,i]\n",
    "\n",
    "    clf = LassoLars(alpha=0.5)\n",
    "    clf.fit(X_train,example_y)\n",
    "    x = clf.coef_\n",
    "    y_pred = np.argmin(residual(example_y,X_train,x,y_train))\n",
    "    print(y_pred, y_test[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now test the whole algorithm with both original and vectorized implementation <br>\n",
    "(The only line of difference is the one where we compute the residuals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Prediction: 0\n",
      "Vectorized Prediction: 0\n",
      "Test passed!\n"
     ]
    }
   ],
   "source": [
    "y = np.array([1, 2, 3])\n",
    "A = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "class_x = np.array([0, 1])\n",
    "\n",
    "def test_algorithm(A, y, class_x, alpha=0.35, max_iter=1000):\n",
    "    # Original version\n",
    "    clf = LassoLars(alpha=alpha, max_iter=max_iter)\n",
    "    clf.fit(A,y)\n",
    "    x = clf.coef_\n",
    "    r = residual(y,A,x,class_x)\n",
    "    # print(r)\n",
    "    pred1 = np.argmin(r)\n",
    "    print(\"Original Prediction:\",pred1)\n",
    "\n",
    "    # Vectorized version\n",
    "    clf_2 = LassoLars(alpha=alpha, max_iter=max_iter)\n",
    "    clf_2.fit(A,y)\n",
    "    x_2 = clf_2.coef_\n",
    "    r_2 = residual_vectorized(y,A,x_2,class_x)\n",
    "    # print(r_2)\n",
    "    pred2 = np.argmin(r_2)\n",
    "    print(\"Vectorized Prediction:\",pred2)\n",
    "    try:\n",
    "        assert np.array_equal(r, r_2), \"Results are not equal\"\n",
    "    except AssertionError as e:\n",
    "        print(e)\n",
    "        print(\"r shape:\", r.shape, \"r_2 shape:\", r_2.shape)\n",
    "        # print(\"r:\", r)\n",
    "        # print(\"r_2:\", r_2)\n",
    "    try:\n",
    "        assert pred1 == pred2, \"Predictions are not equal\"\n",
    "    except AssertionError as e:\n",
    "        print(e)\n",
    "        print(\"pred1:\", pred1, \"pred2:\", pred2)\n",
    "    print(\"Test passed!\")\n",
    "\n",
    "test_algorithm(A, y, class_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test this on the real data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Prediction: 0\n",
      "Vectorized Prediction: 0\n",
      "Results are not equal\n",
      "r shape: (1146,) r_2 shape: (1146,)\n",
      "Test passed!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(xtest\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]):\n\u001b[0;32m      7\u001b[0m     y \u001b[38;5;241m=\u001b[39m xtest[:,i]\n\u001b[1;32m----> 8\u001b[0m     \u001b[43mtest_algorithm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mytrain\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[26], line 10\u001b[0m, in \u001b[0;36mtest_algorithm\u001b[1;34m(A, y, class_x, alpha, max_iter)\u001b[0m\n\u001b[0;32m      8\u001b[0m clf\u001b[38;5;241m.\u001b[39mfit(A,y)\n\u001b[0;32m      9\u001b[0m x \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mcoef_\n\u001b[1;32m---> 10\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mresidual\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mclass_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# print(r)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m pred1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmin(r)\n",
      "Cell \u001b[1;32mIn[11], line 14\u001b[0m, in \u001b[0;36mresidual\u001b[1;34m(y, A, x, class_x)\u001b[0m\n\u001b[0;32m     11\u001b[0m r \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(k)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,k):\n\u001b[1;32m---> 14\u001b[0m     r[i] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(y \u001b[38;5;241m-\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43mclass_x\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)        \n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "xtrain = X_train[:,:1000]\n",
    "ytrain = y_train[:1000]\n",
    "xtest = X_test[:,:10]\n",
    "ytest = y_test[:10]\n",
    "\n",
    "for i in range(xtest.shape[1]):\n",
    "    y = xtest[:,i]\n",
    "    test_algorithm(xtrain, y, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m clf\u001b[38;5;241m.\u001b[39mfit(xtrain,example_y)\n\u001b[0;32m     11\u001b[0m x \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mcoef_\n\u001b[1;32m---> 12\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mresidual\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43mxtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mytrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmin(r)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(y_pred, ytest[i])\n",
      "Cell \u001b[1;32mIn[11], line 14\u001b[0m, in \u001b[0;36mresidual\u001b[1;34m(y, A, x, class_x)\u001b[0m\n\u001b[0;32m     11\u001b[0m r \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(k)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,k):\n\u001b[1;32m---> 14\u001b[0m     r[i] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(y \u001b[38;5;241m-\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43mclass_x\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)        \n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "xtrain = X_train[:,:1000]\n",
    "ytrain = y_train[:1000]\n",
    "xtest = X_test[:,:10]\n",
    "ytest = y_test[:10]\n",
    "\n",
    "cnt = 0\n",
    "for i in range(10):\n",
    "    example_y = xtest[:,i]\n",
    "    clf = LassoLars(alpha=0.01, max_iter=1000)\n",
    "    clf.fit(xtrain,example_y)\n",
    "    x = clf.coef_\n",
    "    r = residual(example_y,xtrain,x,ytrain)\n",
    "    y_pred = np.argmin(r)\n",
    "    print(y_pred, ytest[i])\n",
    "    if y_pred == ytest[i]:\n",
    "        cnt += 1\n",
    "\n",
    "print(f\"{cnt}/10 correct predictions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "985 515\n",
      "199 199\n",
      "291 291\n",
      "654 654\n",
      "485 485\n",
      "141 643\n",
      "146 146\n",
      "146 234\n",
      "253 227\n",
      "54 239\n",
      "5/10 correct predictions\n"
     ]
    }
   ],
   "source": [
    "xtrain = X_train[:,:1000]\n",
    "ytrain = y_train[:1000]\n",
    "xtest = X_test[:,:10]\n",
    "ytest = y_test[:10]\n",
    "\n",
    "cnt = 0\n",
    "for i in range(10):\n",
    "    example_y = xtest[:,i]\n",
    "    clf = LassoLars(alpha=0.01, max_iter=10000)\n",
    "    clf.fit(xtrain,example_y)\n",
    "    x = clf.coef_\n",
    "    r2 = residual_vectorized(example_y,xtrain,x,ytrain)\n",
    "    y_pred = np.argmin(r2)\n",
    "    print(y_pred, ytest[i])\n",
    "    if y_pred == ytest[i]:\n",
    "        cnt += 1\n",
    "        \n",
    "print(f\"{cnt}/10 correct predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 38\u001b[0m\n\u001b[0;32m     35\u001b[0m X \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mcoef_\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Predict the class with the minimum residual for each example\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m residuals \u001b[38;5;241m=\u001b[39m \u001b[43mresidual_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexamples_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# take the minimum residual for each example\u001b[39;00m\n\u001b[0;32m     40\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmin(residuals, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[1;32mIn[29], line 24\u001b[0m, in \u001b[0;36mresidual_matrix\u001b[1;34m(y, A, x, class_x)\u001b[0m\n\u001b[0;32m     21\u001b[0m r \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], k))\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(k):\n\u001b[1;32m---> 24\u001b[0m     diff \u001b[38;5;241m=\u001b[39m y \u001b[38;5;241m-\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelta_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_x\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m     r[:, i] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(diff, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def delta_matrix(x, i, class_num):\n",
    "    \"\"\"\n",
    "    Modified delta function to work with matrix inputs and to select coefficients\n",
    "    associated with the ith class for multiple samples.\n",
    "    \"\"\"\n",
    "    n, m = x.shape[1], len(class_num)\n",
    "    if n != m:\n",
    "        raise ValueError(\"Vectors of different sizes\")\n",
    "    \n",
    "    tmp = (np.subtract(np.multiply(i,np.ones((x.shape[0], n))),class_num)).astype(int)\n",
    "    tmp[tmp == 0] = 1\n",
    "    tmp[tmp != 1] = 0\n",
    "    \n",
    "    return np.multiply(tmp,x).T\n",
    "\n",
    "def residual_matrix(y, A, x, class_x):\n",
    "    \"\"\"\n",
    "    Modified to compute residuals for a batch of examples.\n",
    "    \"\"\"\n",
    "    k = np.max(class_x) + 1\n",
    "    r = np.zeros((y.shape[1], k))\n",
    "    \n",
    "    for i in range(k):\n",
    "        diff = y - np.dot(A, delta_matrix(x, i, class_x))\n",
    "        r[:, i] = np.linalg.norm(diff, axis=0)\n",
    "        \n",
    "    return r\n",
    "\n",
    "# Preparing the data\n",
    "examples_y = X_test[:, :10]\n",
    "\n",
    "# Fit the Lasso model on multiple targets\n",
    "clf = LassoLars(alpha=1, max_iter=10000)\n",
    "clf.fit(X_train, examples_y)\n",
    "X = clf.coef_\n",
    "\n",
    "# Predict the class with the minimum residual for each example\n",
    "residuals = residual_matrix(examples_y, X_train, X, y_train)\n",
    "# take the minimum residual for each example\n",
    "y_pred = np.argmin(residuals, axis=1)\n",
    "\n",
    "for i in range(10):\n",
    "    print(y_pred[i], y_test[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4baeb7825cf248e18b6163173080c8c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6870 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 29\u001b[0m\n\u001b[0;32m     27\u001b[0m y \u001b[38;5;241m=\u001b[39m X_val_fold[:, i]\n\u001b[0;32m     28\u001b[0m clf \u001b[38;5;241m=\u001b[39m LassoLars(alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.35\u001b[39m, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n\u001b[1;32m---> 29\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_fold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m x \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mcoef_\n\u001b[0;32m     31\u001b[0m pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmin(residual_vectorized(y, X_train_fold, x, y_train_fold))\n",
      "File \u001b[1;32md:\\Murgi\\code\\memes2024\\meme-research-2024\\phash\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Murgi\\code\\memes2024\\meme-research-2024\\phash\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:1133\u001b[0m, in \u001b[0;36mLars.fit\u001b[1;34m(self, X, y, Xy)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     noise \u001b[38;5;241m=\u001b[39m rng\u001b[38;5;241m.\u001b[39muniform(high\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjitter, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(y))\n\u001b[0;32m   1131\u001b[0m     y \u001b[38;5;241m=\u001b[39m y \u001b[38;5;241m+\u001b[39m noise\n\u001b[1;32m-> 1133\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1135\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1137\u001b[0m \u001b[43m    \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_normalize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mXy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mXy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32md:\\Murgi\\code\\memes2024\\meme-research-2024\\phash\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:1016\u001b[0m, in \u001b[0;36mLars._fit\u001b[1;34m(self, X, y, max_iter, alpha, fit_path, normalize, Xy)\u001b[0m\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Auxiliary method to fit the model using X, y as training data\"\"\"\u001b[39;00m\n\u001b[0;32m   1014\u001b[0m n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m-> 1016\u001b[0m X, y, X_offset, y_offset, X_scale \u001b[38;5;241m=\u001b[39m \u001b[43m_preprocess_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1017\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy_X\u001b[49m\n\u001b[0;32m   1018\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1021\u001b[0m     y \u001b[38;5;241m=\u001b[39m y[:, np\u001b[38;5;241m.\u001b[39mnewaxis]\n",
      "File \u001b[1;32md:\\Murgi\\code\\memes2024\\meme-research-2024\\phash\\lib\\site-packages\\sklearn\\linear_model\\_base.py:261\u001b[0m, in \u001b[0;36m_preprocess_data\u001b[1;34m(X, y, fit_intercept, normalize, copy, copy_y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    253\u001b[0m     X_offset, X_var, _ \u001b[38;5;241m=\u001b[39m _incremental_mean_and_var(\n\u001b[0;32m    254\u001b[0m         X,\n\u001b[0;32m    255\u001b[0m         last_mean\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    258\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m    259\u001b[0m     )\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 261\u001b[0m     X_offset \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    263\u001b[0m X_offset \u001b[38;5;241m=\u001b[39m X_offset\u001b[38;5;241m.\u001b[39mastype(X\u001b[38;5;241m.\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    264\u001b[0m X \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m X_offset\n",
      "File \u001b[1;32md:\\Murgi\\code\\memes2024\\meme-research-2024\\phash\\lib\\site-packages\\numpy\\lib\\function_base.py:520\u001b[0m, in \u001b[0;36maverage\u001b[1;34m(a, axis, weights, returned, keepdims)\u001b[0m\n\u001b[0;32m    517\u001b[0m     keepdims_kw \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeepdims\u001b[39m\u001b[38;5;124m'\u001b[39m: keepdims}\n\u001b[0;32m    519\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 520\u001b[0m     avg \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mmean(axis, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkeepdims_kw)\n\u001b[0;32m    521\u001b[0m     avg_as_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(avg)\n\u001b[0;32m    522\u001b[0m     scl \u001b[38;5;241m=\u001b[39m avg_as_array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype(a\u001b[38;5;241m.\u001b[39msize\u001b[38;5;241m/\u001b[39mavg_as_array\u001b[38;5;241m.\u001b[39msize)\n",
      "File \u001b[1;32md:\\Murgi\\code\\memes2024\\meme-research-2024\\phash\\lib\\site-packages\\numpy\\core\\_methods.py:118\u001b[0m, in \u001b[0;36m_mean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m    115\u001b[0m         dtype \u001b[38;5;241m=\u001b[39m mu\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf4\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    116\u001b[0m         is_float16_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 118\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, mu\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _no_nep50_warning():\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, matthews_corrcoef, cohen_kappa_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "rskf = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=42)\n",
    "\n",
    "f1_scores = []\n",
    "mcc_scores = []\n",
    "kappa_scores = []\n",
    "\n",
    "for i, (train_index, val_index) in enumerate(rskf.split(X_original, y_original)):\n",
    "    print(f\"Fold {i+1}\")\n",
    "    X_train_fold, X_val_fold = X_original[train_index], X_original[val_index]\n",
    "    y_train_fold, y_val_fold = y_original[train_index], y_original[val_index]\n",
    "\n",
    "    X_train_fold, X_val_fold = stack(X_train_fold,X_val_fold)\n",
    "    \n",
    "    # Normalize data\n",
    "    ss = StandardScaler()\n",
    "    ss.fit(X_train_fold.T)\n",
    "    X_train_fold = ss.transform(X_train_fold.T).T\n",
    "    X_val_fold = ss.transform(X_val_fold.T).T\n",
    "    \n",
    "    y_pred = [] \n",
    "\n",
    "    for i in tqdm(range(X_val_fold.shape[1]), total=X_val_fold.shape[1]):\n",
    "        y = X_val_fold[:, i]\n",
    "        clf = LassoLars(alpha=0.35, max_iter=1000)\n",
    "        clf.fit(X_train_fold, y)\n",
    "        x = clf.coef_\n",
    "        pred = np.argmin(residual_vectorized(y, X_train_fold, x, y_train_fold))\n",
    "        y_pred.append(pred)\n",
    "\n",
    "    f1 = f1_score(y_val_fold, y_pred, average='weighted')\n",
    "    mcc = matthews_corrcoef(y_val_fold, y_pred)\n",
    "    kappa = cohen_kappa_score(y_val_fold, y_pred)\n",
    "    f1_scores.append(f1)\n",
    "    mcc_scores.append(mcc)\n",
    "    kappa_scores.append(kappa)\n",
    "    print(f\"F1 score: {f1}\")\n",
    "    print(f\"MCC score: {mcc}\")\n",
    "    print(f\"Kappa score: {kappa}\")\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log results to MLFlow afterwards, because I forgot to do it before..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.7191368276653454,\n",
       "  0.724320652683042,\n",
       "  0.7154913744956061,\n",
       "  0.7182704955178946,\n",
       "  0.720729646829588,\n",
       "  0.7186103379488686,\n",
       "  0.7212651366697033,\n",
       "  0.7201955152934306,\n",
       "  0.7193276805212179,\n",
       "  0.7206674421691117],\n",
       " [0.7152226837835239,\n",
       "  0.7209402972381975,\n",
       "  0.7127020222295651,\n",
       "  0.713429338577417,\n",
       "  0.7182379981372972,\n",
       "  0.7166919549386346,\n",
       "  0.7163003308387714,\n",
       "  0.7154605331373134,\n",
       "  0.716062855958425,\n",
       "  0.7182949377816343],\n",
       " [0.6926658191903892,\n",
       "  0.698055322018478,\n",
       "  0.6893170747158672,\n",
       "  0.6902912069749074,\n",
       "  0.6958256724057834,\n",
       "  0.6944132248226206,\n",
       "  0.6936854502258498,\n",
       "  0.6929570530919471,\n",
       "  0.6926223415290162,\n",
       "  0.6952438807475023])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../reports/f1_scores.txt\", 'r') as f:\n",
    "    f1_scores = f.readlines()\n",
    "    f1_scores = [float(score.strip()) for score in f1_scores]\n",
    "\n",
    "with open(\"../reports/mcc_scores.txt\", 'r') as f:\n",
    "    mcc_scores = f.readlines()\n",
    "    mcc_scores = [float(score.strip()) for score in mcc_scores]\n",
    "\n",
    "with open(\"../reports/kappa_scores.txt\", 'r') as f:\n",
    "    kappa_scores = f.readlines()\n",
    "    kappa_scores = [float(score.strip()) for score in kappa_scores]\n",
    "\n",
    "f1_scores, mcc_scores, kappa_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import dagshub\n",
    "import constants\n",
    "import os\n",
    "\n",
    "mlflow.set_tracking_uri('https://dagshub.com/levente-murgas/meme-research-2024.mlflow')\n",
    "# os.environ['MLFLOW_TRACKING_URI']=f\"'https://dagshub.com/levente-murgas/meme-research-2024.mlflow'\"\n",
    "\n",
    "# # Recommended to define as environment variables\n",
    "os.environ['MLFLOW_TRACKING_USERNAME'] = constants.MLFLOW_TRACKING_USERNAME\n",
    "os.environ['MLFLOW_TRACKING_PASSWORD'] = constants.MLFLOW_TRACKING_PASSWORD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "def get_experiment_id(name):\n",
    "    exp = mlflow.get_experiment_by_name(name)\n",
    "    if exp is None:\n",
    "      exp_id = mlflow.create_experiment(name)\n",
    "      return exp_id\n",
    "    return exp.experiment_id\n",
    "\n",
    "exp_id = get_experiment_id(\"sparse-matching2\")\n",
    "print(exp_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'lassolars_model'.\n",
      "2024/04/08 17:23:05 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: lassolars_model, version 1\n",
      "Created version '1' of model 'lassolars_model'.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoLars\n",
    "\n",
    "clf = LassoLars(alpha=0.35, max_iter=1000)\n",
    "\n",
    "with  mlflow.start_run(experiment_id=exp_id):\n",
    "    mlflow.log_params({\n",
    "        \"featuresize\": (64,64),\n",
    "        \"alpha\": 0.35,\n",
    "        \"maxiter\": 1000,\n",
    "        \"nsplits\": 5,\n",
    "        \"nrepeats\": 2\n",
    "    })\n",
    "\n",
    "    for i in range(10):\n",
    "        logged_f1 = f1_scores[i]\n",
    "        logged_mcc = mcc_scores[i]\n",
    "        logged_kappa = kappa_scores[i]\n",
    "        mlflow.log_metrics({\n",
    "            \"f1weighted\": logged_f1,\n",
    "            \"mcc\": logged_mcc,\n",
    "            \"kappa\": logged_kappa\n",
    "        }, step=i)\n",
    "\n",
    "    model_info = mlflow.sklearn.log_model(\n",
    "        sk_model=clf,\n",
    "        artifact_path=\"lassolars_model\",\n",
    "        registered_model_name=\"lassolars_model\",\n",
    "    )\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dagshub-meme-research-2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
