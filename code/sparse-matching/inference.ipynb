{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd\n",
    "%cd d:\\\\Murgi\\\\code\\\\memes2024\\\\meme-research-2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import normalize\n",
    "import time\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.linear_model import Lasso, LassoLars\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meme_df = pd.read_parquet('./data/meme_entries.parquet')\n",
    "template_df = pd.read_parquet('./data/meme_template_links.parquet')\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "meme_df['template_id'] = labelencoder.fit_transform(meme_df['template_name'])\n",
    "meme_df['template_id'] = meme_df['template_id'] + 1\n",
    "sample_size = 30\n",
    "sampled_meme_df = meme_df.groupby('template_name').apply(lambda x: x.sample(n=min(sample_size, len(x)),random_state=42))\n",
    "sampled_meme_df = sampled_meme_df.reset_index(drop=True)\n",
    "sampled_meme_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack(X_train,X_test):\n",
    "    X_toconcat_train = [np.reshape(e,(X_train[0].shape[0]*X_train[0].shape[1],1)) for e in X_train]\n",
    "    X_toconcat_test = [np.reshape(e,(X_train[0].shape[0]*X_train[0].shape[1],1)) for e in X_test]\n",
    "    \n",
    "    Xtrain = np.concatenate(X_toconcat_train,axis=1) # Each column is now an image of the train set\n",
    "    Xtest = np.concatenate(X_toconcat_test,axis=1) # Each column is now an image of the test set\n",
    "    return Xtrain, Xtest\n",
    "\n",
    "def stack2(X_train):\n",
    "    X_toconcat_train = [np.reshape(e,(X_train[0].shape[0]*X_train[0].shape[1],1)) for e in X_train]\n",
    "    Xtrain = np.concatenate(X_toconcat_train,axis=1) # Each column is now an image of the train set\n",
    "    return Xtrain\n",
    "    \n",
    "def single_stack(image):\n",
    "    # Check if 'image' is a list; if not, wrap it in a list\n",
    "    if not isinstance(image, list):\n",
    "        image = [image]\n",
    "    # Reshape and stack as before\n",
    "    X_toconcat = [np.reshape(e, (e.shape[0] * e.shape[1], 1)) for e in image]\n",
    "    return np.concatenate(X_toconcat, axis=1)  # Each column is now an image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images(meme_df, target_size=(64,64), filter=Image.LANCZOS):\n",
    "    '''\n",
    "    Read the images from the meme_df dataframe and return the images and the labels\n",
    "    - meme_df: dataframe containing the path to the images and the template_id\n",
    "    - target_size: size of the output images (default is (128,128))\n",
    "    - filter: filter to use for resizing (default is Image.LANCZOS)\n",
    "    '''\n",
    "    path_list = meme_df['path'].tolist()\n",
    "    template_list = meme_df['template_id'].tolist()\n",
    "    X,y = [], []\n",
    "    for (path, template) in tqdm(zip(path_list, template_list), total= len(path_list)):\n",
    "        try:\n",
    "            im = Image.open(path) \n",
    "            im = im.convert(\"L\")\n",
    "            # resize to given size (if given) and check that it's the good size\n",
    "            im = im.resize(target_size, resample=filter)\n",
    "            X.append(np.asarray(im, dtype=np.uint8))\n",
    "            y.append(template)\n",
    "        except IOError:\n",
    "            pass\n",
    "        except:\n",
    "            print(\"Unexpected error:\", sys.exc_info()[0])\n",
    "            raise\n",
    "    print(\"Images uploaded !\")\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def read_image(path, target_size=(64,64), filter=Image.NEAREST):\n",
    "    im = Image.open(path) \n",
    "    im = im.convert(\"L\")\n",
    "    # resize to given size (if given) and check that it's the good size\n",
    "    im = im.resize(target_size, resample=filter)\n",
    "    return np.asarray(im, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_vectorized(y, A, x, class_x):\n",
    "    '''\n",
    "    Returns the residuals of the model for each class\n",
    "    n: number of features, m: number of samples\n",
    "    - y: the target vector, shape (n,)\n",
    "    - A: training images, shape (n, m)\n",
    "    - x: the coefficients, shape (m,)\n",
    "    - class_x: the train labels, shape: (m,) type: list\n",
    "    '''\n",
    "    # Generate the delta matrix for all classes\n",
    "    delta_matrix = delta_vectorized(x, class_x)\n",
    "    \n",
    "    # Compute the predicted values for each class\n",
    "    predictions = np.dot(A, delta_matrix)\n",
    "    \n",
    "    # Calculate the errors by subtracting y from each column of predictions\n",
    "    # Note: Need to reshape y to broadcast correctly against predictions\n",
    "    errors = predictions - y.reshape(-1, 1)\n",
    "    \n",
    "    # Calculate the norm of errors for each class to get the residuals\n",
    "    r = np.linalg.norm(errors, axis=0)\n",
    "    \n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta_vectorized(x, class_num):\n",
    "    '''\n",
    "    Function that selects the coefficients associated with the ith class\n",
    "    Useful for SCI calculation\n",
    "    m: number of samples\n",
    "    - x: vector of coefficients, shape (m,)\n",
    "    - class_num: vector of training labels, shape (m,)\n",
    "    '''\n",
    "    n, m = len(x), len(class_num)\n",
    "    \n",
    "    if (n != m):\n",
    "        print('Vectors of different sizes')\n",
    "\n",
    "    k = np.max(class_num)+1\n",
    "\n",
    "    tmp = np.subtract(np.multiply(np.ones((n, k)),np.arange(k)),class_num[:, np.newaxis])\n",
    "    tmp = np.where(tmp == 0, 1, 0)\n",
    "    \n",
    "    return (tmp * x[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "save_path_X = \"./data/X_original_64x64_sampled_30.pkl\"\n",
    "save_path_y = \"./data/y_original_64x64_sampled_30.pkl\"\n",
    "load_df = sampled_meme_df\n",
    "\n",
    "if os.path.exists(save_path_X):\n",
    "    print(\"Load\")\n",
    "    X_original = pkl.load(open(save_path_X, 'rb'))\n",
    "    y_original = pkl.load(open(save_path_y, 'rb'))\n",
    "\n",
    "else:\n",
    "    # X_original, y_original = read_images(load_df, filter=Image.NEAREST)\n",
    "    with open(save_path_X, 'wb') as f:\n",
    "        pkl.dump(X_original, f)\n",
    "\n",
    "    with open(save_path_y, 'wb') as f:\n",
    "        pkl.dump(y_original, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_df = pd.read_parquet(r\"data\\touch\\facebook.parquet\")\n",
    "twitter_df = pd.read_parquet(r\"data\\touch\\twitter.parquet\")\n",
    "reddit_df = pd.read_parquet(r\"data\\touch\\reddit.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_df=fb_df.rename(columns={\"filepath\":\"path\"})\n",
    "fb_df.loc[:,\"path\"] =  fb_df.loc[:,\"path\"].apply(lambda x: x.replace(\"D:\\\\Facebook2023\",\"D:\\\\Murgi\\\\Facebook2023\\\\Facebook2023\"))\n",
    "fb_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df=twitter_df.rename(columns={\"filepath\":\"path\"})\n",
    "twitter_df.loc[:,\"path\"] =  twitter_df.loc[:,\"path\"].apply(lambda x: x.replace(\"D:\\\\Twitter2023\",\"D:\\\\Murgi\\\\Twitter2023\"))\n",
    "twitter_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_dir = 'C:\\\\Users\\\\molontay\\\\Murgi\\\\data\\\\Memes2022Final2\\\\Memes2022Final2\\\\' \n",
    "files = os.listdir(reddit_dir)\n",
    "id_to_files = {os.path.splitext(file)[0]:file for file in files}\n",
    "\n",
    "reddit_df['path'] = reddit_df['id'].apply(lambda x: os.path.join(reddit_dir,id_to_files[x]) if id_to_files[x] else None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(123)\n",
    "\n",
    "all_reddit_memes = reddit_df['path'].tolist()\n",
    "sample_reddit_memes = random.sample(all_reddit_memes, 1000)\n",
    "rest_reddit_memes = list(set(all_reddit_memes) - set(sample_reddit_memes))\n",
    "\n",
    "all_fb_memes = fb_df['path'].tolist()\n",
    "sample_fb_memes = random.sample(all_fb_memes, 1000)\n",
    "rest_fb_memes = list(set(all_reddit_memes) - set(sample_fb_memes))\n",
    "\n",
    "\n",
    "all_twitter_memes = twitter_df['path'].tolist()\n",
    "sample_twitter_memes = random.sample(all_twitter_memes, 1000)\n",
    "rest_twitter_memes = list(set(all_twitter_memes) - set(sample_twitter_memes))\n",
    "\n",
    "all_the_rest = rest_reddit_memes + rest_fb_memes + rest_twitter_memes\n",
    "random.shuffle(all_the_rest)\n",
    "\n",
    "\n",
    "X_paths = sample_reddit_memes + sample_fb_memes + sample_twitter_memes + all_the_rest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90ff0c5d89274a1781ffae1d665198e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm.contrib.concurrent import  thread_map, process_map  # or thread_map\n",
    "\n",
    "\n",
    "X_stacked = stack2(X_original)\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_stacked.T)\n",
    "X_scaled = ss.transform(X_stacked.T).T\n",
    "\n",
    "def predict(path:str,X_scaled,y_original,ss:StandardScaler):\n",
    "    img = read_image(path)\n",
    "    img_stacked = single_stack(img)\n",
    "    img_scaled = ss.transform(img_stacked.T).T\n",
    "\n",
    "    clf = LassoLars(alpha=0.35, max_iter=1000)\n",
    "    clf.fit(X_scaled,img_scaled)\n",
    "    x = clf.coef_\n",
    "    pred = np.argmin(residual_vectorized(img_scaled, X_scaled, x, y_original))\n",
    "    with open(\"sparse_matching_sm_preds.txt\",\"a\") as f:\n",
    "        f.write(f\"{path}\\t{pred}\\n\")\n",
    "    return (path,pred)\n",
    "\n",
    "\n",
    "\n",
    "# Run inference on X_paths using thread_map\n",
    "results = thread_map(lambda path: predict(path, X_scaled, y_original, ss), X_paths[:5])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phash",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
