{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_from_txt_file(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        memes = f.readlines()\n",
    "\n",
    "    path_hash_dict = {}\n",
    "    for line in memes:\n",
    "        path, _hash = line.split(\"\\t\")\n",
    "        path = path.replace(\"\\\\\", \"/\")\n",
    "        path_hash_dict[path] = _hash.strip()\n",
    "\n",
    "    df = pd.DataFrame.from_dict(path_hash_dict, orient=\"index\", columns=[\"phash\"])\n",
    "    df.reset_index(inplace=True)\n",
    "    df.columns = [\"path\", \"phash\"]\n",
    "    try:\n",
    "        df[\"template\"] = df[\"path\"].apply(lambda x: x.split(\"/\")[-2] if \"Memes2023_splitted\" in x else None) \n",
    "    except Exception as e:\n",
    "        print(\"Error at row: \",df[\"path\"])\n",
    "        raise e\n",
    "    return df\n",
    "\n",
    "def write_back_df_to_txt(df, outpath):\n",
    "    with open(outpath, \"w\") as f:\n",
    "        for row in df.itertuples():\n",
    "            # get the index of the row\n",
    "            try:\n",
    "                idx = row.Index\n",
    "                # write the idx and the phash to the file\n",
    "                f.write(f\"{df.loc[idx,'path']}\\t{df.loc[idx,'phash']}\\n\")\n",
    "            except Exception as e:\n",
    "                print(\"Error at row: \",row,idx)\n",
    "                raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>template_name</th>\n",
       "      <th>path</th>\n",
       "      <th>phash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-days-without-lenny-simpsons</td>\n",
       "      <td>0-days-without-lenny-simpsons</td>\n",
       "      <td>D:/Memes2024/0-days-without-Lenny-Simpsons/0-d...</td>\n",
       "      <td>0fe9b236e884fc38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0-days-without-Lenny-Simpsons_23</td>\n",
       "      <td>0-days-without-lenny-simpsons</td>\n",
       "      <td>D:/Memes2024/0-days-without-Lenny-Simpsons/0-d...</td>\n",
       "      <td>07e5ba2ee806fe30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0-days-without-Lenny-Simpsons_1</td>\n",
       "      <td>0-days-without-lenny-simpsons</td>\n",
       "      <td>D:/Memes2024/0-days-without-Lenny-Simpsons/0-d...</td>\n",
       "      <td>1fed3226e804fe38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0-days-without-Lenny-Simpsons_24</td>\n",
       "      <td>0-days-without-lenny-simpsons</td>\n",
       "      <td>D:/Memes2024/0-days-without-Lenny-Simpsons/0-d...</td>\n",
       "      <td>07e1b83ee886fa38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0-days-without-Lenny-Simpsons_10</td>\n",
       "      <td>0-days-without-lenny-simpsons</td>\n",
       "      <td>D:/Memes2024/0-days-without-Lenny-Simpsons/0-d...</td>\n",
       "      <td>17e5b22ee806fe30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0-days-without-Lenny-Simpsons_25</td>\n",
       "      <td>0-days-without-lenny-simpsons</td>\n",
       "      <td>D:/Memes2024/0-days-without-Lenny-Simpsons/0-d...</td>\n",
       "      <td>17e1ba2ee806fa38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0-days-without-Lenny-Simpsons_27</td>\n",
       "      <td>0-days-without-lenny-simpsons</td>\n",
       "      <td>D:/Memes2024/0-days-without-Lenny-Simpsons/0-d...</td>\n",
       "      <td>0fedb236e806fa30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0-days-without-Lenny-Simpsons_26</td>\n",
       "      <td>0-days-without-lenny-simpsons</td>\n",
       "      <td>D:/Memes2024/0-days-without-Lenny-Simpsons/0-d...</td>\n",
       "      <td>17edb226e884fe30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0-days-without-Lenny-Simpsons_28</td>\n",
       "      <td>0-days-without-lenny-simpsons</td>\n",
       "      <td>D:/Memes2024/0-days-without-Lenny-Simpsons/0-d...</td>\n",
       "      <td>0fe9b236e886f829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0-days-without-Lenny-Simpsons_3</td>\n",
       "      <td>0-days-without-lenny-simpsons</td>\n",
       "      <td>D:/Memes2024/0-days-without-Lenny-Simpsons/0-d...</td>\n",
       "      <td>0fedb236e806fa30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id                  template_name  \\\n",
       "0     0-days-without-lenny-simpsons  0-days-without-lenny-simpsons   \n",
       "1  0-days-without-Lenny-Simpsons_23  0-days-without-lenny-simpsons   \n",
       "2   0-days-without-Lenny-Simpsons_1  0-days-without-lenny-simpsons   \n",
       "3  0-days-without-Lenny-Simpsons_24  0-days-without-lenny-simpsons   \n",
       "4  0-days-without-Lenny-Simpsons_10  0-days-without-lenny-simpsons   \n",
       "5  0-days-without-Lenny-Simpsons_25  0-days-without-lenny-simpsons   \n",
       "6  0-days-without-Lenny-Simpsons_27  0-days-without-lenny-simpsons   \n",
       "7  0-days-without-Lenny-Simpsons_26  0-days-without-lenny-simpsons   \n",
       "8  0-days-without-Lenny-Simpsons_28  0-days-without-lenny-simpsons   \n",
       "9   0-days-without-Lenny-Simpsons_3  0-days-without-lenny-simpsons   \n",
       "\n",
       "                                                path             phash  \n",
       "0  D:/Memes2024/0-days-without-Lenny-Simpsons/0-d...  0fe9b236e884fc38  \n",
       "1  D:/Memes2024/0-days-without-Lenny-Simpsons/0-d...  07e5ba2ee806fe30  \n",
       "2  D:/Memes2024/0-days-without-Lenny-Simpsons/0-d...  1fed3226e804fe38  \n",
       "3  D:/Memes2024/0-days-without-Lenny-Simpsons/0-d...  07e1b83ee886fa38  \n",
       "4  D:/Memes2024/0-days-without-Lenny-Simpsons/0-d...  17e5b22ee806fe30  \n",
       "5  D:/Memes2024/0-days-without-Lenny-Simpsons/0-d...  17e1ba2ee806fa38  \n",
       "6  D:/Memes2024/0-days-without-Lenny-Simpsons/0-d...  0fedb236e806fa30  \n",
       "7  D:/Memes2024/0-days-without-Lenny-Simpsons/0-d...  17edb226e884fe30  \n",
       "8  D:/Memes2024/0-days-without-Lenny-Simpsons/0-d...  0fe9b236e886f829  \n",
       "9  D:/Memes2024/0-days-without-Lenny-Simpsons/0-d...  0fedb236e806fa30  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meme_df = pd.read_parquet(\"data/meme_entries.parquet\")\n",
    "meme_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train and test stratified by template\n",
    "train_df, test_df = train_test_split(meme_df, test_size=0.2, random_state=42, stratify=meme_df[\"template_name\"])\n",
    "\n",
    "# write back to txt files\n",
    "train_outpath = \"./data/phashes/imgflip_cluster_phashes.txt\"\n",
    "test_outpath = \"./data/phashes/imgflip_annotate_phashes.txt\"\n",
    "write_back_df_to_txt(train_df, train_outpath)\n",
    "write_back_df_to_txt(test_df, test_outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "facebook_file = \"./data/phashes/social-media/facebook_phashes.txt\"\n",
    "reddit_file = \"./data/phashes/social-media/reddit_phashes.txt\"\n",
    "twitter_file = \"./data/phashes/social-media/twitter_phashes.txt\"\n",
    "imgflip_cluster_file = train_outpath\n",
    "\n",
    "merged_cluster_file = \"./data/phashes/imgflip_plus_sm_to_cluster.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines to add:  99360\n",
      "Lines to add:  236357\n",
      "Lines to add:  955654\n",
      "Lines to add:  174339\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def add_to_clustering(file_to_add, clustering_file):\n",
    "    with open(file_to_add, \"r\") as add_f:\n",
    "        lines = add_f.readlines()\n",
    "    print(\"Lines to add: \", len(lines))\n",
    "\n",
    "    with open(clustering_file, \"a\") as f:\n",
    "        for line in lines:\n",
    "            f.write(line)\n",
    "            \n",
    "add_to_clustering(imgflip_cluster_file, merged_cluster_file)\n",
    "add_to_clustering(facebook_file, merged_cluster_file)\n",
    "add_to_clustering(reddit_file, merged_cluster_file)\n",
    "add_to_clustering(twitter_file, merged_cluster_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>phash</th>\n",
       "      <th>template</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D:/Memes2024/UNO-Draw-25-Cards/UNO-Draw-25-Car...</td>\n",
       "      <td>93c9dc8d240aea7b</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D:/Memes2024/Peter-parker-reading-a-book/Peter...</td>\n",
       "      <td>c57a6ca563962a65</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D:/Memes2024/Daring-today-arent-we-squidward/D...</td>\n",
       "      <td>713230b47efa8c33</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D:/Memes2024/Sidious-Error/Sidious-Error_63.jpg</td>\n",
       "      <td>99c96721abc18b9b</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D:/Memes2024/They-took-our-jobs-stance-South-P...</td>\n",
       "      <td>ab3245cc9cd96635</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465705</th>\n",
       "      <td>D:/Murgi/Twitter2023/2020_6-36655.jpg</td>\n",
       "      <td>bb839b1a2598837b</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465706</th>\n",
       "      <td>D:/Murgi/Twitter2023/2019_6-28933.jpg</td>\n",
       "      <td>e73199e7618c7096</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465707</th>\n",
       "      <td>D:/Murgi/Twitter2023/2020_6-6090.jpg</td>\n",
       "      <td>d78c9adb2da44525</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465708</th>\n",
       "      <td>D:/Murgi/Twitter2023/2020_6-27653.jpg</td>\n",
       "      <td>f98a0ef5626e6641</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465709</th>\n",
       "      <td>D:/Murgi/Twitter2023/2019_6-19928.jpg</td>\n",
       "      <td>776724ad89839393</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1465710 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      path             phash  \\\n",
       "0        D:/Memes2024/UNO-Draw-25-Cards/UNO-Draw-25-Car...  93c9dc8d240aea7b   \n",
       "1        D:/Memes2024/Peter-parker-reading-a-book/Peter...  c57a6ca563962a65   \n",
       "2        D:/Memes2024/Daring-today-arent-we-squidward/D...  713230b47efa8c33   \n",
       "3          D:/Memes2024/Sidious-Error/Sidious-Error_63.jpg  99c96721abc18b9b   \n",
       "4        D:/Memes2024/They-took-our-jobs-stance-South-P...  ab3245cc9cd96635   \n",
       "...                                                    ...               ...   \n",
       "1465705              D:/Murgi/Twitter2023/2020_6-36655.jpg  bb839b1a2598837b   \n",
       "1465706              D:/Murgi/Twitter2023/2019_6-28933.jpg  e73199e7618c7096   \n",
       "1465707               D:/Murgi/Twitter2023/2020_6-6090.jpg  d78c9adb2da44525   \n",
       "1465708              D:/Murgi/Twitter2023/2020_6-27653.jpg  f98a0ef5626e6641   \n",
       "1465709              D:/Murgi/Twitter2023/2019_6-19928.jpg  776724ad89839393   \n",
       "\n",
       "        template  \n",
       "0           None  \n",
       "1           None  \n",
       "2           None  \n",
       "3           None  \n",
       "4           None  \n",
       "...          ...  \n",
       "1465705     None  \n",
       "1465706     None  \n",
       "1465707     None  \n",
       "1465708     None  \n",
       "1465709     None  \n",
       "\n",
       "[1465710 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_cluster_df = create_df_from_txt_file(merged_cluster_file)\n",
    "to_cluster_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zsavvas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
